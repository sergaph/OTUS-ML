{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='otus.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры задач:\n",
    "\n",
    "- ранжировать документы по степени релевантности заданной теме (тематический поиск);\n",
    "- ранжировать документы по степени тематического сходства с заданным документом или его фрагментом;\n",
    "- построить иерархический тематический каталог коллекции документов и выработать правила каталогизации новых документов;\n",
    "- определить, как темы изменялись со временем (предполагается, что для каждого документа известно время его создания);\n",
    "- определить тематику авторов (предполагается, что для каждого документа известен список авторов);\n",
    "- определить тематику различных сущностей (entities), связанных с документами (например, журналов, конференций, организаций, стран);\n",
    "- разбить документ на тематически однородные фрагменты.\n",
    "\n",
    "\n",
    "[источник](http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "библиотеки:\n",
    "- pyLDAvis\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- gensim\n",
    "- nltk\n",
    "- bigARTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/dmitrys/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitrys/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример анализ тем в статьях NIPS\n",
    "\n",
    "## https://www.kaggle.com/benhamner/nips-papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nips-papers/papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7241, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1002</td>\n",
       "      <td>1994</td>\n",
       "      <td>Using a neural net to instantiate a deformable...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002-using-a-neural-net-to-instantiate-a-defor...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>U sing a neural net to instantiate a\\ndeformab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1003</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003-plasticity-mediated-competitive-learning.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning\\n\\nTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1004</td>\n",
       "      <td>1994</td>\n",
       "      <td>ICEG Morphology Classification using an Analog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004-iceg-morphology-classification-using-an-a...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>ICEG Morphology Classification using an\\nAnalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1005</td>\n",
       "      <td>1994</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma Using Ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005-real-time-control-of-a-tokamak-plasma-usi...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1006</td>\n",
       "      <td>1994</td>\n",
       "      <td>Pulsestream Synapses with Non-Volatile Analogu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006-pulsestream-synapses-with-non-volatile-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "5  1002  1994  Using a neural net to instantiate a deformable...        NaN   \n",
       "6  1003  1994           Plasticity-Mediated Competitive Learning        NaN   \n",
       "7  1004  1994  ICEG Morphology Classification using an Analog...        NaN   \n",
       "8  1005  1994  Real-Time Control of a Tokamak Plasma Using Ne...        NaN   \n",
       "9  1006  1994  Pulsestream Synapses with Non-Volatile Analogu...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "5  1002-using-a-neural-net-to-instantiate-a-defor...  Abstract Missing   \n",
       "6  1003-plasticity-mediated-competitive-learning.pdf  Abstract Missing   \n",
       "7  1004-iceg-morphology-classification-using-an-a...  Abstract Missing   \n",
       "8  1005-real-time-control-of-a-tokamak-plasma-usi...  Abstract Missing   \n",
       "9  1006-pulsestream-synapses-with-non-volatile-an...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  \n",
       "5  U sing a neural net to instantiate a\\ndeformab...  \n",
       "6  Plasticity-Mediated Competitive Learning\\n\\nTe...  \n",
       "7  ICEG Morphology Classification using an\\nAnalo...  \n",
       "8  Real-Time Control of a Tokamak Plasma\\nUsing N...  \n",
       "9  Real-Time Control of a Tokamak Plasma\\nUsing N...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # Remove new line characters\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    # Remove distracting single quotes\n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def doc_to_words(doc, stop_words, lemma):\n",
    "    stop_words = set(stop_words)\n",
    "    # remove stop words and punctuation\n",
    "    words = [w for w in gensim.utils.simple_preprocess(str(doc), deacc=True) if w not in stop_words]\n",
    "    \n",
    "    # make lemmatization\n",
    "    words = [lemma.lemmatize(w) for w in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self',\n",
      " 'organization',\n",
      " 'associative',\n",
      " 'database',\n",
      " 'application',\n",
      " 'hisashi',\n",
      " 'suzuki',\n",
      " 'suguru',\n",
      " 'arimoto',\n",
      " 'osaka',\n",
      " 'university',\n",
      " 'toyonaka',\n",
      " 'osaka',\n",
      " 'japan',\n",
      " 'abstract',\n",
      " 'efficient',\n",
      " 'method',\n",
      " 'self',\n",
      " 'organizing',\n",
      " 'associative',\n",
      " 'database',\n",
      " 'proposed',\n",
      " 'together',\n",
      " 'application',\n",
      " 'robot',\n",
      " 'eyesight',\n",
      " 'system',\n",
      " 'proposed',\n",
      " 'database',\n",
      " 'associate',\n",
      " 'input',\n",
      " 'output',\n",
      " 'first',\n",
      " 'half',\n",
      " 'part',\n",
      " 'discussion',\n",
      " 'algorithm',\n",
      " 'self',\n",
      " 'organization',\n",
      " 'proposed']\n"
     ]
    }
   ],
   "source": [
    "if prepare:\n",
    "    # Convert to list\n",
    "    data = df.paper_text.values.tolist()\n",
    "\n",
    "    data = [clean(t) for t in data]\n",
    "    data_words = [doc_to_words(t, stop_words, lemma) for t in data]\n",
    "    \n",
    "    with open('data.pkl', 'wb') as f:\n",
    "        pickle.dump({'data': data, 'data_words': data_words}, f)\n",
    "else:\n",
    "    with open('data.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        data = d['data']\n",
    "        data_words = d['data_words']\n",
    "\n",
    "pprint(data_words[0][:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare:\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    bigram_mod.save('bigram_mod.pkl')\n",
    "    \n",
    "    data_words_bigrams = [bigram_mod[w] for w in data_words]\n",
    "    with open('bigrams.pkl', 'wb') as f:\n",
    "        pickle.dump(data_words_bigrams, f)\n",
    "\n",
    "else:\n",
    "    bigram_mod = gensim.models.Phrases.load('bigram_mod.pkl')\n",
    "    \n",
    "    with open('bigrams.pkl', 'rb') as f:\n",
    "        data_words_bigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self_organization',\n",
       " 'associative',\n",
       " 'database',\n",
       " 'application',\n",
       " 'hisashi',\n",
       " 'suzuki',\n",
       " 'suguru',\n",
       " 'arimoto',\n",
       " 'osaka',\n",
       " 'university']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_bigrams[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare:\n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "    id2word.save('id2word.pkl')\n",
    "else:\n",
    "    id2word = corpora.Dictionary.load('id2word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in data_words_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (5, 6),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 3),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actual'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'767 SELF-ORGANIZATION OF ASSOCIATIVE DATABASE AND ITS APPLICATIONS Hisashi Suzuki and Suguru Arimoto Osaka University, Toyonaka, Osaka 560, Japan ABSTRACT An efficient method of self-organizing associative databases is proposed together with applications to robot eyesight systems. The proposed databases can associate any input with some output. In the first half part of discussion, an algorithm of self-organization is proposed. From an aspect of hardware, it produces a new style of neural network. In the latter half part, an applicability to handwritten letter recognition and that to an autonomous mobile robot system are demonstrated. INTRODUCTION Let a mapping f : X -+ Y be given. Here, X is a finite or infinite set, and Y is another finite or infinite set. A learning machine observes any set of pairs (x, y) sampled randomly from X x Y. (X x Y means the Cartesian product of X and Y.) And, it computes some estimate j : X -+ Y of f to make small, the estimation error in some measure. Usually we say that: the faster the decrease of estimation error with increase of the number of samples, the better the learning machine. However, such expression on performance is incomplete. Since, it lacks consideration on the candidates of J of j assumed preliminarily. Then, how should we find out good learning machines? To clarify this conception, let us discuss for a while on some types of learning machines. And, let us advance the understanding of the self-organization of associative database . . Parameter Type An ordinary type of learning machine assumes an equation relating xs and ys with parameters being indefinite, namely, a structure of f. It is equivalent to define implicitly a set F of candidates of (F is some subset of mappings from X to Y.) And, it computes values of the parameters based on the observed samples. We call such type a parameter type. For a learning machine defined well, if F 3 f, j approaches f as the number of samples increases. In the alternative case, however, some estimation error remains eternally. Thus, a problem of designing a learning machine returns to find out a proper structure of f in this sense. On the other hand, the assumed structure of f is demanded to be as compact as possible to achieve a fast learning. In other words, the number of parameters should be small. Since, if the parameters are few, some j can be uniquely determined even though the observed samples are few. However, this demand of being proper contradicts to that of being compact. Consequently, in the parameter type, the better the compactness of the assumed structure that is proper, the better the learning machine. This is the most elementary conception when we design learning machines . 1. . Universality and Ordinary Neural Networks Now suppose that a sufficient knowledge on f is given though J itself is unknown. In this case, it is comparatively easy to find out proper and compact structures of J. In the alternative case, however, it is sometimes difficult. A possible solution is to give up the compactness and assume an almighty structure that can cover various 1s. A combination of some orthogonal bases of the infinite dimension is such a structure. Neural networks 1 ,2 are its approximations obtained by truncating finitely the dimension for implementation. ? American Institute of Physics 1988 768 A main topic in designing neural networks is to establish such desirable structures of 1. This work includes developing practical procedures that compute values of coefficients from the observed samples. Such discussions are :flourishing since 1980 while many efficient methods have been proposed. Recently, even hardware units computing coefficients in parallel for speed-up are sold, e.g., ANZA, Mark III, Odyssey and E-1. Nevertheless, in neural networks, there always exists a danger of some error remaining eternally in estimating /. Precisely speaking, suppose that a combination of the bases of a finite number can define a structure of 1 essentially. In other words, suppose that F 3 /, or 1 is located near F. In such case, the estimation error is none or negligible. However, if 1 is distant from F, the estimation error never becomes negligible. Indeed, many researches report that the following situation appears when 1 is too complex. Once the estimation error converges to some value (> 0) as the number of samples increases, it decreases hardly even though the dimension is heighten. This property sometimes is a considerable defect of neural networks . . Recursi ve Type The recursive type is founded on another methodology of learning that should be as follows. At the initial stage of no sample, the set Fa (instead of notation F) of candidates of I equals to the set of all mappings from X to Y. After observing the first sample (Xl, Yl) E X x Y, Fa is reduced to Fi so that I(xt) = Yl for any I E F. After observing the second sample (X2 Y2) E X x Y, Fl is further reduced to F2 so that i(xt) = Yl and I(X2) = Y2 for any I E F. Thus, the candidate set F becomes gradually small as observation of samples proceeds. The after observing i-samples, which we write is one of the most likelihood estimation of 1 selected in fi;. Hence, contrarily to the parameter type, the recursive type guarantees surely that j approaches to 1 as the number of samples increases. The recursive type, if observes a sample (x\" yd, rewrites values 1,-l(X),S to I,(x)s for some xs correlated to the sample. Hence, this type has an architecture composed of a rule for rewriting and a free memory space. Such architecture forms naturally a kind of database that builds up management systems of data in a self-organizing way. However, this database differs from ordinary ones in the following sense. It does not only record the samples already observed, but computes some estimation of l(x) for any x E X. We call such database an associative database. The first subject in constructing associative databases is how we establish the rule for rewri ting. For this purpose, we adap t a measure called the dissimilari ty. Here, a dissimilari ty means a mapping d : X x X -+ {reals > O} such that for any (x, x) E X x X, d(x, x) > 0 whenever l(x) t /(x). However, it is not necessarily defined with a single formula. It is definable with, for example, a collection of rules written in forms of \"if? .. then?? .. \" The dissimilarity d defines a structure of 1 locally in X x Y. Hence, even though the knowledge on f is imperfect, we can re:flect it on d in some heuristic way. Hence, contrarily to neural networks, it is possible to accelerate the speed of learning by establishing d well. Especially, we can easily find out simple ds for those ls which process analogically information like a human. (See the applications in this paper.) And, for such /s, the recursive type shows strongly its effectiveness. We denote a sequence of observed samples by (Xl, Yd, (X2 Y2),???. One of the simplest constructions of associative databases after observing i-samples (i = 1,2,.,,) is as follows. i i\" I, Algorithm 1. At the initial stage, let So be the empty set. For every i = 1,2\" .. , let i,-l(x) for any x E X equal some y* such that (x*,y*) E S,-l and d(x, x*) = min (%,y)ES.-t d(x, x) . Furthermore, add (x\" y,) to S;-l to produce Sa, i.e., S, = S,_l U {(x\" (1) y,n. 769 Another version improved to economize the memory is as follows. Algorithm 2, At the initial stage, let So be composed of an arbitrary element in X x Y. For every i = 1,2\"\", let ii-lex) for any x E X equal some y. such that (x?, y.) E Si-l and d(x, x?) = min d(x, x) . (i,i)ES.-l Furthermore, if ii-l(Xi) # Yi then let Si = Si-l, or add (Xi, Yi) to Si-l to produce Si, i.e., Si = Si-l U {(Xi, Yi)} In either construction, ii approaches to f as i increases. However, the computation time grows proportionally to the size of Si. The second subject in constructing associative databases is what addressing rule we should employ to economize the computation time. In the subsequent chapters, a construction of associative database for this purpose is proposed. It manages data in a form of binary tree. SELF-ORGANIZATION OF ASSOCIATIVE DATABASE Given a sample sequence (Xl, Yl), (X2 Y2), .. \" the algorithm for constructing associative database is as follows. Algorithm 3, Step I(Initialization): Let (x[root], y[root]) = (Xl, Yd. Here, x[.] and y[.] are variables assigned for respective nodes to memorize data.. Furthermore, let t = 1. Step 2: Increase t by 1, and put x, in. After reset a pointer n to the root, repeat the following until n arrives at some terminal node, i.e., leaf. Notations nand d(xt, x[n)), let n n mean the descendant nodes of n. =n. Otherwise, let n =n. If d(x\" r[n)) ~ Step 3: Display yIn] as the related information. Next, put y, in. If yIn] = y\" back to step 2. Otherwise, first establish new descendant nodes n and n. Secondly, let (x[n], yIn)) (x[n], yIn)) (x[n], yIn)), (Xt, y,). (2) (3) Finally, back to step 2. Here, the loop of step 2-3 can be stopped at any time and also can be continued. Now, suppose that gate elements, namely, artificial \"synapses\" that play the role of branching by d are prepared. Then, we obtain a new style of neural network with gate elements being randomly connected by this algorithm. LETTER RECOGNITION Recen tly, the vertical slitting method for recognizing typographic English letters3 , the elastic matching method for recognizing hand written discrete English letters4 , the global training and fuzzy logic search method for recognizing Chinese characters written in square styleS, etc. are published. The self-organization of associative database realizes the recognition of handwritten continuous English letters. 770 9 /wn\" NOV ~ ~ ~ -xk :La.t ~~ ~ ~~~ dw1lo ~~~~~of~~ ~~~ 4,-?~~4Fig. 1. Source document. 2~~--------------- lOO~--------------- H o o Fig. 2. Windowing. 1000 2000 3000 4000 Number of samples o 1000 2000 3000 4000 NUAlber of sampl es Fig. 3. An experiment result. An image scanner takes a document image (Fig. 1). The letter recognizer uses a parallelogram window that at least can cover the maximal letter (Fig. 2), and processes the sequence of letters while shifting the window. That is, the recognizer scans a word in a slant direction. And, it places the window so that its left vicinity may be on the first black point detected. Then, the window catches a letter and some part of the succeeding letter. If recognition of the head letter is performed, its end position, namely, the boundary line between two letters becomes known. Hence, by starting the scanning from this boundary and repeating the above operations, the recognizer accomplishes recursively the task. Thus the major problem comes to identifying the head letter in the window. Considering it, we define the following. ? Regard window images as xs, and define X accordingly. ? For a (x, x) E X x X, denote by B a black point in the left area from the boundary on window image X. Project each B onto window image x. Then, measure the Euclidean distance 6 between fj and a black point B on x being the closest to B. Let d(x, x) be the summation of 6s for all black points Bs on x divided by the number of Bs. ? Regard couples of the \"reading\" and the position of boundary as ys, and define Y accordingly. An operator teaches the recognizer in interaction the relation between window image and reading& boundary with algorithm 3. Precisely, if the recalled reading is incorrect, the operator teaches a correct reading via the console. Moreover, if the boundary position is incorrect, he teaches a correct position via the mouse. Fig. 1 shows partially a document image used in this experiment. Fig. 3 shows the change of the number of nodes and that of the recognition rate defined as the relative frequency of correct answers in the past 1000 trials. Speciiications of the window are height = 20dot, width = 10dot, and slant angular = 68deg. In this example, the levels of tree were distributed in 6-19 at time 4000 and the recognition rate converged to about 74%. Experimentally, the recognition rate converges to about 60-85% in most cases, and to 95% at a rare case. However, it does not attain 100% since, e.g., \"c\" and \"e\" are not distinguishable because of excessive lluctuation in writing. If the consistency of the x, y-relation is not assured like this, the number of nodes increases endlessly (d. Fig. 3). Hence, it is clever to stop the learning when the recognition rate attains some upper limit. To improve further the recognition rate, we must consider the spelling of words. It is one of future subjects. 771 OBSTACLE AVOIDING MOVEMENT Various systems of camera type autonomous mobile robot are reported flourishingly6-1O. The system made up by the authors (Fig. 4) also belongs to this category. Now, in mathematical methodologies, we solve usually the problem of obstacle avoiding movement as a cost minimization problem under some cost criterion established artificially. Contrarily, the self-organization of associative database reproduces faithfully the cost criterion of an operator. Therefore, motion of the robot after learning becomes very natural. Now, the length, width and height of the robot are all about O.7m, and the weight is about 30kg. The visual angle of camera is about 55deg. The robot has the following three factors of motion. It turns less than ?30deg, advances less than 1m, and controls speed less than 3km/h. The experiment was done on the passageway of wid th 2.5m inside a building which the authors laboratories exist in (Fig. 5). Because of an experimental intention, we arrange boxes, smoking stands, gas cylinders, stools, handcarts, etc. on the passage way at random. We let the robot take an image through the camera, recall a similar image, and trace the route preliminarily recorded on it. For this purpose, we define the following. ? Let the camera face 28deg downward to take an image, and process it through a low pass filter. Scanning vertically the filtered image from the bottom to the top, search the first point C where the luminance changes excessively. Then, su bstitu te all points from the bottom to C for white, and all points from C to the top for black (Fig. 6). (If no obstacle exists just in front of the robot, the white area shows the free area where the robot can move around.) Regard binary 32 x 32dot images processed thus as xs, and define X accordingly. ? For every (x, x) E X x X, let d(x, x) be the number of black points on the exclusive-or image between x and X. ? Regard as ys the images obtained by drawing routes on images xs, and define Y accordingly. The robot superimposes, on the current camera image x, the route recalled for x, and inquires the operator instructions. The operator judges subjectively whether the suggested route is appropriate or not. In the negative answer, he draws a desirable route on x with the mouse to teach a new y to the robot. This opera.tion defines implicitly a sample sequence of (x, y) reflecting the cost criterion of the operator. .::l\" ! - IibUBe _. - 22 11 Roan 12 {- 13 Stationary uni t Fig. 4. Configuration of autonomous mobile robot system. ~ I , 23 24 North 14 rmbi Ie unit (robot) - Roan y t Fig. 5. Experimental environment. 772 Wall Camera image Preprocessing A ::: !fa ? Preprocessing 0 O Course suggest ion ?? .. Search A Fig. 6. Processing for obstacle avoiding movement. x Fig. 1. Processing for position identification. We define the satisfaction rate by the relative frequency of acceptable suggestions of route in the past 100 trials. In a typical experiment, the change of satisfaction rate showed a similar tendency to Fig. 3, and it attains about 95% around time 800. Here, notice that the rest 5% does not mean directly the percentage of collision. (In practice, we prevent the collision by adopting some supplementary measure.) At time 800, the number of nodes was 145, and the levels of tree were distributed in 6-17. The proposed method reflects delicately various characters of operator. For example, a robot trained by an operator 0 moves slowly with enough space against obstacles while one trained by another operator 0 brushes quickly against obstacles. This fact gives us a hint on a method of printing \"characters\" into machines. POSITION IDENTIFICATION The robot can identify its position by recalling a similar landscape with the position data to a camera image. For this purpose, in principle, it suffices to regard camera images and position data as xs and ys, respectively. However, the memory capacity is finite in actual compu ters. Hence, we cannot but compress the camera images at a slight loss of information. Such compression is admittable as long as the precision of position identification is in an acceptable area. Thus, the major problem comes to find out some suitable compression method. In the experimental environment (Fig. 5), juts are on the passageway at intervals of 3.6m, and each section between adjacent juts has at most one door. The robot identifies roughly from a surrounding landscape which section itself places in. And, it uses temporarily a triangular surveying technique if an exact measure is necessary. To realize the former task, we define the following . ? Turn the camera to take a panorama image of 360deg. Scanning horizontally the center line, substitute the points where the luminance excessively changes for black and the other points for white (Fig. 1). Regard binary 360dot line images processed thus as xs, and define X accordingly. ? For every (x, x) E X x X, project each black point A on x onto x. And, measure the Euclidean distance 6 between A and a black point A on x being the closest to A. Let the summation of 6 be S. Similarly, calculate S by exchanging the roles of x and X. Denoting the numbers of As and As respectively by nand n, define 773 d(x, x) = ~(~ + ~). 2 n n (4) ? Regard positive integers labeled on sections as ys (cf. Fig. 5), and define Y accordingly. In the learning mode, the robot checks exactly its position with a counter that is reset periodically by the operator. The robot runs arbitrarily on the passageways within 18m area and learns the relation between landscapes and position data. (Position identification beyond 18m area is achieved by crossing plural databases one another.) This task is automatic excepting the periodic reset of counter, namely, it is a kind of learning without teacher. We define the identification rate by the relative frequency of correct recalls of position data in the past 100 trials. In a typical example, it converged to about 83% around time 400. At time 400, the number of levels was 202, and the levels oftree were distributed in 522. Since the identification failures of 17% can be rejected by considering the trajectory, no pro blem arises in practical use. In order to improve the identification rate, the compression ratio of camera images must be loosened. Such possibility depends on improvement of the hardware in the future. Fig. 8 shows an example of actual motion of the robot based on the database for obstacle avoiding movement and that for position identification. This example corresponds to a case of moving from 14 to 23 in Fig. 5. Here, the time interval per frame is about 40sec. ,~. .~ ( ;~\"i.. ~ \" \" . ..I I ? ? \" I . .1 t ; i -: , . . , II Fig. 8. Actual motion of the robot. 774 CONCLUSION A method of self-organizing associative databases was proposed with the application to robot eyesight systems. The machine decomposes a global structure unknown into a set of local structures known and learns universally any input-output response. This framework of problem implies a wide application area other than the examples shown in this paper. A defect of the algorithm 3 of self-organization is that the tree is balanced well only for a subclass of structures of f. A subject imposed us is to widen the class. A probable solution is to abolish the addressing rule depending directly on values of d and, instead, to establish another rule depending on the distribution function of values of d. It is now under investigation. REFERENCES 1. Hopfield, J. J. and D. W. Tank, \"Computing with Neural Circuit: A Model/ Science 233 (1986), pp. 625-633. 2. Rumelhart, D. E. et al., \"Learning Representations by Back-Propagating Errors,\" Nature 323 (1986), pp. 533-536. 3. Hull, J. J., \"Hypothesis Generation in a Computational Model for Visual Word Recognition,\" IEEE Expert, Fall (1986), pp. 63-70. 4. Kurtzberg, J. M., \"Feature Analysis for Symbol Recognition by Elastic Matching,\" IBM J. Res. Develop. 31-1 (1987), pp. 91-95. 5. Wang, Q. R. and C. Y. Suen, \"Large Tree Classifier with Heuristic Search and Global Training,\" IEEE Trans. Pattern. Anal. & Mach. Intell. PAMI 9-1 (1987) pp. 91-102. 6. Brooks, R. A. et al, \"Self Calibration of Motion and Stereo Vision for Mobile Robots,\" 4th Int. Symp. of Robotics Research (1987), pp. 267-276. 7. Goto, Y. and A. Stentz, \"The CMU System for Mobile Robot Navigation,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 99-105. 8. Madarasz, R. et al., \"The Design of an Autonomous Vehicle for the Disabled,\" IEEE Jour. of Robotics & Automation RA 2-3 (1986), pp. 117-125. 9. Triendl, E. and D. J. Kriegman, \"Stereo Vision and Navigation within Buildings,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 1725-1730. 10. Turk, M. A. et al., \"Video Road-Following for the Autonomous Land Vehicle,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 273-279. '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].count('accordingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=20, \n",
    "        random_state=100,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True)\n",
    "    lda_model.save('lda_default.pkl')\n",
    "else:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel.load('lda_default.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.045*\"time\" + 0.037*\"signal\" + 0.026*\"noise\" + 0.020*\"source\" + '\n",
      "  '0.020*\"domain\" + 0.016*\"event\" + 0.014*\"filter\" + 0.013*\"frequency\" + '\n",
      "  '0.013*\"system\" + 0.011*\"speech\"'),\n",
      " (1,\n",
      "  '0.022*\"pi\" + 0.018*\"ai\" + 0.015*\"ii\" + 0.011*\"vi\" + 0.011*\"al\" + 0.011*\"mi\" '\n",
      "  '+ 0.010*\"pr\" + 0.009*\"pu\" + 0.009*\"sr\" + 0.008*\"hi\"'),\n",
      " (2,\n",
      "  '0.292*\"group\" + 0.067*\"interaction\" + 0.047*\"streaming\" + 0.043*\"protein\" + '\n",
      "  '0.042*\"stream\" + 0.025*\"site\" + 0.021*\"grouping\" + 0.018*\"binding\" + '\n",
      "  '0.017*\"overlapping\" + 0.011*\"gy\"'),\n",
      " (3,\n",
      "  '0.042*\"map\" + 0.036*\"region\" + 0.023*\"motion\" + 0.022*\"field\" + '\n",
      "  '0.021*\"point\" + 0.020*\"local\" + 0.018*\"location\" + 0.014*\"figure\" + '\n",
      "  '0.012*\"energy\" + 0.012*\"surface\"'),\n",
      " (4,\n",
      "  '0.063*\"learning\" + 0.036*\"loss\" + 0.036*\"label\" + 0.035*\"class\" + '\n",
      "  '0.029*\"classifier\" + 0.029*\"classification\" + 0.023*\"example\" + '\n",
      "  '0.017*\"training\" + 0.012*\"function\" + 0.012*\"algorithm\"'),\n",
      " (5,\n",
      "  '0.016*\"node\" + 0.016*\"graph\" + 0.014*\"algorithm\" + 0.014*\"set\" + '\n",
      "  '0.012*\"model\" + 0.009*\"tree\" + 0.008*\"edge\" + 0.007*\"number\" + '\n",
      "  '0.007*\"structure\" + 0.007*\"problem\"'),\n",
      " (6,\n",
      "  '0.023*\"data\" + 0.018*\"feature\" + 0.014*\"method\" + 0.013*\"task\" + '\n",
      "  '0.012*\"performance\" + 0.012*\"test\" + 0.012*\"model\" + 0.011*\"set\" + '\n",
      "  '0.011*\"training\" + 0.010*\"using\"'),\n",
      " (7,\n",
      "  '0.042*\"model\" + 0.017*\"task\" + 0.016*\"control\" + 0.014*\"system\" + '\n",
      "  '0.013*\"human\" + 0.012*\"learning\" + 0.010*\"figure\" + 0.010*\"trajectory\" + '\n",
      "  '0.009*\"feedback\" + 0.008*\"prediction\"'),\n",
      " (8,\n",
      "  '0.021*\"algorithm\" + 0.019*\"problem\" + 0.018*\"function\" + 0.017*\"method\" + '\n",
      "  '0.012*\"optimization\" + 0.009*\"solution\" + 0.009*\"gradient\" + 0.009*\"linear\" '\n",
      "  '+ 0.009*\"kernel\" + 0.007*\"convex\"'),\n",
      " (9,\n",
      "  '0.020*\"bound\" + 0.015*\"theorem\" + 0.014*\"log\" + 0.011*\"function\" + '\n",
      "  '0.011*\"result\" + 0.010*\"let\" + 0.010*\"distribution\" + 0.010*\"sample\" + '\n",
      "  '0.009*\"case\" + 0.009*\"probability\"'),\n",
      " (10,\n",
      "  '0.039*\"cell\" + 0.036*\"response\" + 0.021*\"stimulus\" + 0.021*\"visual\" + '\n",
      "  '0.021*\"model\" + 0.014*\"attention\" + 0.011*\"spatial\" + 0.010*\"information\" + '\n",
      "  '0.010*\"unit\" + 0.009*\"receptive_field\"'),\n",
      " (11,\n",
      "  '0.034*\"neuron\" + 0.016*\"time\" + 0.015*\"dynamic\" + 0.014*\"neural\" + '\n",
      "  '0.013*\"activity\" + 0.013*\"network\" + 0.010*\"input\" + 0.009*\"pattern\" + '\n",
      "  '0.009*\"model\" + 0.008*\"state\"'),\n",
      " (12,\n",
      "  '0.118*\"matrix\" + 0.035*\"sparse\" + 0.023*\"vector\" + 0.019*\"column\" + '\n",
      "  '0.018*\"data\" + 0.016*\"low\" + 0.015*\"subspace\" + 0.015*\"analysis\" + '\n",
      "  '0.014*\"entry\" + 0.014*\"noise\"'),\n",
      " (13,\n",
      "  '0.076*\"image\" + 0.028*\"object\" + 0.022*\"model\" + 0.016*\"convolutional\" + '\n",
      "  '0.015*\"feature\" + 0.013*\"recognition\" + 0.011*\"pixel\" + '\n",
      "  '0.010*\"representation\" + 0.010*\"visual\" + 0.008*\"using\"'),\n",
      " (14,\n",
      "  '0.052*\"state\" + 0.042*\"policy\" + 0.033*\"action\" + 0.028*\"learning\" + '\n",
      "  '0.025*\"reward\" + 0.023*\"agent\" + 0.016*\"value\" + 0.016*\"function\" + '\n",
      "  '0.015*\"reinforcement\" + 0.012*\"optimal\"'),\n",
      " (15,\n",
      "  '0.029*\"memory\" + 0.016*\"bit\" + 0.015*\"distributed\" + 0.015*\"parallel\" + '\n",
      "  '0.014*\"system\" + 0.013*\"communication\" + 0.012*\"code\" + 0.011*\"time\" + '\n",
      "  '0.011*\"computation\" + 0.010*\"implementation\"'),\n",
      " (16,\n",
      "  '0.047*\"cluster\" + 0.046*\"clustering\" + 0.042*\"distance\" + 0.040*\"point\" + '\n",
      "  '0.039*\"data\" + 0.024*\"metric\" + 0.021*\"embedding\" + 0.020*\"space\" + '\n",
      "  '0.019*\"mean\" + 0.016*\"algorithm\"'),\n",
      " (17,\n",
      "  '0.076*\"network\" + 0.032*\"neural\" + 0.026*\"input\" + 0.026*\"layer\" + '\n",
      "  '0.023*\"learning\" + 0.020*\"training\" + 0.020*\"output\" + 0.019*\"unit\" + '\n",
      "  '0.018*\"weight\" + 0.014*\"deep\"'),\n",
      " (18,\n",
      "  '0.048*\"model\" + 0.025*\"distribution\" + 0.014*\"data\" + 0.013*\"log\" + '\n",
      "  '0.012*\"parameter\" + 0.012*\"inference\" + 0.011*\"variable\" + 0.011*\"gaussian\" '\n",
      "  '+ 0.010*\"likelihood\" + 0.010*\"latent\"'),\n",
      " (19,\n",
      "  '0.061*\"algorithm\" + 0.038*\"xt\" + 0.022*\"time\" + 0.021*\"online\" + '\n",
      "  '0.017*\"game\" + 0.016*\"stochastic\" + 0.015*\"arm\" + 0.015*\"learning\" + '\n",
      "  '0.012*\"strategy\" + 0.012*\"setting\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -10.48982175017813\n",
      "\n",
      "Coherence Score:  0.487366949616273\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.01658643),\n",
       " (5, 0.044622492),\n",
       " (6, 0.027334329),\n",
       " (7, 0.0396485),\n",
       " (8, 0.27373648),\n",
       " (9, 0.076953515),\n",
       " (14, 0.43688047),\n",
       " (17, 0.062421918),\n",
       " (19, 0.017954744)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_document_topics(corpus[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generalization in Reinforcement Learning: Safely Approximating the Value Function Justin A. Boyan and Andrew W. Moore Computer Science Department Carnegie Mellon University Pittsburgh, PA 15213 jab@cs.cmu.edu, awm@cs.cmu .edu Abstract A straightforward approach to the curse of dimensionality in reinforcement learning and dynamic programming is to replace the lookup table with a generalizing function approximator such as a neural net. Although this has been successful in the domain of backgammon, there is no guarantee of convergence. In this paper, we show that the combination of dynamic programming and function approximation is not robust, and in even very benign cases, may produce an entirely wrong policy. We then introduce Grow-Support, a new algorithm which is safe from divergence yet can still reap the benefits of successful generalization . 1 INTRODUCTION Reinforcement learning-the problem of getting an agent to learn to act from sparse, delayed rewards-has been advanced by techniques based on dynamic programming (DP). These algorithms compute a value function which gives, for each state, the minimum possible long-term cost commencing in that state. For the high-dimensional and continuous state spaces characteristic of real-world control tasks, a discrete representation of the value function is intractable; some form of generalization is required. A natural way to incorporate generalization into DP is to use a function approximator, rather than a lookup table, to represent the value function. This approach, which dates back to uses of Legendre polynomials in DP [Bellman et al., 19631, has recently worked well on several dynamic control problems [Mahadevan and Connell, 1990, Lin, 1993] and succeeded spectacularly on the game of backgammon [Tesauro, 1992, Boyan, 1992]. On the other hand, many sensible implementations have been less successful [Bradtke, 1993, Schraudolph et al., 1994]. Indeed, given the well-established success 370 Justin Boyan, Andrew W. Moore on backgammon, the absence of similarly impressive results appearing for other games is perhaps an indication that using function approximation in reinforcement learning does not always work well. In this paper, we demonstrate that the straightforward substitution of function approximators for lookup tables in DP is not robust and, even in very benign cases, may diverge, resulting in an entirely wrong control policy. We then present Grow-Support, a new algorithm designed to converge robustly. Grow-Support grows a collection of states over which function approximation is stable. One-step backups based on Bellman error are not used; instead, values are assigned by performing \"rollouts\" -explicit simulations with a greedy policy. We discuss potential computational advantages of this method and demonstrate its success on some example problems for which the conventional DP algorithm fails. 2 DISCRETE AND SMOOTH VALUE ITERATION Many popular reinforcement learning algorithms, including Q-Iearning and TD(O), are based on the dynamic programmin~ algorithm known as value iteration [Watkins, 1989, Sutton, 1988, Barto et al., 1989J, which for clarity we will call discrete value iteration. Discrete value iteration takes as input a complete model of the world as a Markov Decision Task, and computes the optimal value function J*: J* (x) = the minimum possible sum of future costs starting from x To assure that J* is well-defined, we assume here that costs are nonnegative and that some absorbing goal state-with all future costs O-is reachable from every state. For simplicity we also assume that state transitions are deterministic. Note that J* and the world model together specify a \"greedy\" policy which is optimal for the domain: optimal action from state x = argmin(CosT(x, a) + J*(NEXT-STATE(X, a))) aEA We now consider extending discrete value iteration to the continuous case: we replace the lookup table over all states with a function approximator trained over a sample of states. The smooth value iteration algorithm is given in the appendix. Convergence is no longer guaranteed; we instead recognize four possible classes of behavior: good convergence The function approximator accurately represents the intermediate value functions at each iteration (that is, after m iterations, the value function correctly represents the cost of the cheapest m-step path), and successfully converges to the optimal J* value function. lucky convergence The function approximator does not accurately represent the intermediate value functions at each iteration; nevertheless, the algorithm manages to converge to a value function whose greedy policy is optimal. bad convergence The algorithm converges, i.e. the target J-values for the N training points stop changing, but the resulting value function and policy are poor. divergence Worst of all: small fitter errors may become magnified from one iteration to the next, resulting in a value function which never stops changing. The hope is that the intermediate value functions will be smooth and we will achieve \"good convergence.\" Unfortunately, our experiments have generated all four of these behaviors-and the divergent behavior occurs frequently, even for quite simple problems. Generalization in Reinforcement Learning: Safely Approximating the Value Function 2.1 37 J DIVERGENCE IN SMOOTH VALUE ITERATION We have run simulations in a variety of domains-including a continuous gridworld, a car-on-the-hill problem with nonlinear dynamics, and tic-tac-toe versus a stochastic opponent-and using a variety of function approximators, including polynomial regression, backpropagation, and local weighted regression. In our experiments, none of these function approximators was immune from divergence. The first set ofresults is from the 2-D continuous gridworld, described in Figure 1. By quantizing the state space into a 100 x 100 grid, we can compute J* with discrete value iteration, as shown in Figure 2. The optimal value function is exactly linear: J*(x, y) = 20 - lOx - lOy. Since J* is linear, one would hope smooth value iteration could converge to it with a function approximator as simple as linear or quadratic regression. However, the intermediate value functions of Figure 2 are not smooth and cannot be fit accurately by a low-order polynomial. Using linear regression on a sample of 256 randomly-chosen states, smooth value iteration took over 500 iterations before \"luckily\" converging to optimal. Quadratic regression, though it always produces a smaller fit error than linear regression, did not converge (Figure 3). The quadratic function, in trying to both be flat in the middle of state space and bend down toward 0 at the goal corner, must compensate by underestimating the values at the corner opposite the goal. These underestimates then enlarge on each iteration, as the one-step DP lookaheads erroneously indicate that points can lower their expected cost-to-go by stepping farther away from the goal. The resulting policy is anti-optimal. fontinuous Gridworld J*(x,y) 0.8 0.6 >. 0.4 0.2 0L-0~.~2-0~.~4-0~.~6~0~.~8~1 x Figure 1: In the continuous gridworld domain, the state is a point (x, y) E [0,1]2. There are four actions corresponding to short steps (length 0.05, cost 0.5) in each compass direction, and the goal region is the upper right-hand corner. l*(x, y) is linear. Iteration 12 Iteration 25 .8 1 Figure 2: Computation of 1* by discrete value iteration Iteration 40 Justin Boyan, Andrew W. Moore 372 Iteration 17 Iteration 43 Iteration 127 1 .8 .8 .8 1 Figure 3: Divergence of smooth value iteration with quadratic regression (note z-axis). J*(x , y) Iteration 144 o. o. >. o. .8 o. 0.20 . 40.60 . 8 x 1 1 Figure 4: The 2-D continuous gridworld with puddles, its optimal value function, and a diverging approximation of the value function by Local Weighted Regression (note z-axis). car- o n-the-Hill J* (pa s, vel) 0.5 pas Figure 5: The car-on-the-hill domain. When the velocity is below a threshold, the car must reverse up the left hill to gain enough speed to reach the goal, so r is discontinuous. Iteration 11 Iterati on 101 Iteration 201 Figure 6: Divergerice oYsmooth value iteration wit~ for car-on-th~~hill~ The neural net, a 2-layer MLP with 80 hidden units, was trained for 2000 epochs per iteration. It may seem as though the divergence of smooth value iteration shown above can be attributed to the global nature of polynomial regression. In fact, when the domain is made slightly less trivial, the same types of instabilities appear with even a highly Generalization in Reinforcement Learning: Safely Approximating the Value Function 373 Table 1: Summary of convergence results: Smooth value iteration Domain 2-D grid world 2-D puddle world Car-on-the-hill Linear lucky Quadratic diverge - - - - LWR good diverge good Backprop lucky diverge diverge local memory-based function approximator such as local weighted regression (LWR) [Cleveland and Delvin, 1988]. Figure 4 shows the continuous gridworld augmented to include two oval \"puddles\" through which it is costly to step. Although LWR can fit the corresponding J* function nearly perfectly, smooth value iteration with LWR nonetheless reliably diverges. On another two-dimensional domain, the car-on-the-hill (Figure 5), smooth value iteration with LWR did converge, but a neural net trained by backpropagation did not (see Figure 6) . Table 1 summarizes our results . In light of such experiments, we conclude that the straightforward combination of DP and function approximation is not robust. A general-purpose learning method will require either using a function approximator constrained to be robust during DP [Yee, 1992], or an algorithm which explicitly prevents divergence even in the face of imperfect function approximation, such as the Grow-Support algorithm we present in Section 3. 2.2 RELATED WORK Theoretically, it is not surprising that inserting a smoothing process into a recursive DP procedure can lead to trouble. In [Thrun and Schwartz, 1993] one case is analyzed with the assumption that errors due to function approximation bias are independently distributed. Another area of theoretical analysis concerns inadequately approximated J* functions. In [Singh and Yee, 1994] and [Williams, 1993] bounds are derived for the maximum reduction in optimality that can be produced by a given error in function approximation. If a basis function approximator is used, then the reduction can be large [Sabes, 1993]. These results assume generalization from a dataset containing true optimal values; the true reinforcement learning scenario is even harder because each iteration of DP requires its own function approximation. 3 THE GROW-SUPPORT ALGORITHM The Grow-Support algorithm is designed to construct the optimal value function with a generalizing function approximator while being robust and stable. It recognizes that function approximators cannot always be relied upon to fit the intermediate value functions produced by DP. Instead, it assumes only that the function approximator can represent the final J* function accurately. The specific principles of Grow-Support are these: 1. We maintain a \"support\" set of states whose final J* values have been computed, starting with goal states, and growing this set out from the goal. The fitter is trained only on these values, which we assume it is capable of fitting. 2. Instead of propagating values by one-step DP backups, we use simulations with the current greedy policy, called \"rollouts\". They explicitly verify the achievability of a states cost-to-go estimate before adding that state to the 374 Justin Boyan, Andrew W. Moore support. In a rollout, the J values are derived from costs of actual paths to the goal, not from the values of the previous iterations function approximation. This prevents divergence . 3. We take maximum advantage of generalization. Each iteration, we add to the support set any sample state which can, by executing a single action, reach a state that passes the rollout test. In a discrete environment, this would cause the support set to expand in one-step concentric \"shells\" back from the goal. But in our continuous case, the function approximator may be able to extrapolate correctly well beyond the support region-and when this happens, we can add many points to the support set at once. This leads to the very desirable behavior that the support set grows in big jumps in regions where the value function is smooth. Iteration 1, I Support I =4 Iteration 2, 1Support 1=12 Iteration 3, ISupportl=256 Figure 7: Grow-Support with quadratic regression on the gridworld. (Compare Figure 3.) Iteration 1, I Support I =3 Iteration 2, ISupportl=213 Iteration 5, ISupportl=253 Figure 8: Grow-Support with LWR on the two-puddle gridworld. (Compare Figure 4.) Iteration 3, I Support I =79 Iteration 8, ISupportl=134 Iteration 14, ISupportl=206 3 O. 2 O. -2 o. Figure 9: Grow-Support with backprop on car-on-the-hill. (Compare Figure 6.) The algorithm, again restricted to the deterministic case for simplicity, is outlined in the appendix. In Figures 7-9, we illustrate its convergence on the same combinations of domain and function approximator which caused smooth value iteration to diverge. In Figure 8, all but three points are added to the support within only five iterations, Generalization in Reinforcement Learning: Safely Approximating the Value Function 375 and the resulting greedy policy is optimal. In Figure 9, after 14 iterations, the algorithm terminates. Although 50 states near the discontinuity were not added to the support set, the resulting policy is optimal within the support set. Grow-support converged to a near-optimal policy for all the problems and fitters in Table 1. The Grow-Support algorithm is more robust than value iteration. Empirically, it was also seen to be no more computationally expensive (and often much cheaper) despite the overhead of performing rollouts. Reasons for this are (1) the rollout test is not expensive; (2) once a state has been added to the support, its value is fixed and it needs no more computation; and most importantly, (3) the aggressive exploitation of generalization enables the algorithm to converge in very few iterations. However, with a nondeterministic problem, where multiple rollouts are required to assess the accuracy of a prediction, Grow-Support would become more expensive. It is easy to prove that Grow-Support will always terminate after a finite number of iterations. If the function approximator is inadequate for representing the J* function, Grow-Support may terminate before adding all sample states to the support set. When this happens, we then know exactly which of the sample states are having trouble and which have been learned. This suggests potential schemes for adaptively adding sample states to the support in problematic regions. Investigation of these ideas is in progress. In conclusion, we have demonstrated that dynamic programming methods may diverge when their tables are replaced by generalizing function approximators. Our Grow-Support algorithm uses rollouts, rather than one-step backups, to assign training values and to keep inaccurate states out of the training set. We believe these principles will contribute substantially to producing practical, robust, reinforcement learning. Acknowledgements We thank Scott Fahlman, Geoff Gordon, Mary Lee, Michael Littman and Marc Ringuette for their suggestions, and the NDSEG fellowship and NSF Grant IRI-9214873 for their support. APPENDIX: ALGORITHMS Smooth Value Iteration(X, G, A, NEXT-STATE, COST, FITJ): Given: _ a finite collection of states X = {Xl, X2, .. . XN} sampled from the continuous state space X C fR n , and goal region G C X _ a finite set of allowable actions A _ a deterministic transition function NEXT-STATE: X x A -+ X _ the I-step cost function COST: X x A -+ fR _ a smoothing function approximator FIT J iter := 0 ]<0) [i] := 0 Vi = 1 ... N {X I t-+ J?(iter) [1] } repeat !rain ~ITJ(iter) to approximate the training set: : Iter .:= Iter + 1; XN t-+ /iter)[N] for ~ := 1 ... N do .(iter) [.] ._ { 0 . J 1.minaEA (COST(Xi,a) + FITJ(lter-I)(NEXT-STATE(xi,a))) until j array stops changing if Xi E G otherwise 376 Justin Boyan, Andrew W. Moore subroutine RoIloutCost(x, J): Starting from state x , follow the greedy policy defined by value function J until either reaching the goal, or exceeding a total path cost of J(x) + ?. Then return: --t the actual total cost of the path, if goal is reached from x with cost ~ J(x) + e --t 00, if goal is not reached in cost J(x) + ?. Grow-Support(X,G,A, NEXT-STATE, COST, FITJ): Given: ? exactly the same inputs as Smooth Value Iteration. SUPPORT := {(Xi t-+ 0) I Xi E G} repeat Train FIT J to approximate the training set SUPPORT for each Xi ~ SUPPORT do c := minaEA [COsT(xi,a) + RolloutCost(NEXT-STATE(Xi, a), FITJ)] if c < 00 then add (Xi t-+ c) to the training set SUPPORT until SUPPORT stops growing or includes all sample points. References [Barto et al., 1989] A . Barto, R. Sutton , and C . Watkins . Learning and sequential decision making. Technical Report COINS 89- 95, Univ. of Massachusetts, 1989 . [Bellman et al., 1963] R . Bellman, R . Kalaba, and B . Kotkin. Polynomial approximation-a new computational technique in dynamic programming: Allocation processes . Mathematics of Computation, 17, 1963. [Boyan , 1992] J. A . Boyan. Modular neural networks for learning context-dependent game strategies . Masters thesis, Cambridge University, 1992. [Bradtke, 1993] S. J. Bradtke. Reinforcement learning applied to linear quadratic regulation. In S. J . Hanson, J . Cowan, and C . L . Giles, editors, NIPS-5. Morgan Kaufmann , 1993. [Cleveland and Delvin, 1988] W . S. Cleveland and S. J. Delvin. Locally weighted regression : An approach to regression analysis by local fitting. JASA , 83(403):596-610, September 1988. [Lin, 1993] L.-J . Lin . Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, 1993. [Mahadevan and Connell , 1990] S. Mahadevan and J. Connell . Automatic programming of behavior-based robots using reinforcement learning. Technical report, IBM T. J . Watson Research Center, NY 10598, 1990 . [Sabes, 1993] P. Sabes . Approximating Q-values with basis function represent ations. In Proceedings of the Fourth C onnectionist Models Summer School, 1993. [Schraudolph et al., 1994] N . Schraudolph, P . Dayan, and T. Sejnowski . Using TD(>.) to learn an evaluation function for the game of Go . In J. D. Cowan, G . Tesauro , and J . Alspector, editors, NIPS-6. Morgan Kaufmann, 1994. [Singh and Yee, 1994] S. P. Singh and R. Yee. An upper bound on the loss from approximate optimal-value functions . Machine Learning, 1994. Technical Note (to appear) . [Sutton, 1988] R . Sutton . Learning to predict by the methods of temporal differences. Machine Learning, 3,1988. [Tesauro, 1992] G. Tesauro. Practical issues in temporal difference learning. Machine Learning, 8(3/4), May 1992. [Thrun and Schwartz, 1993] S. Thrun and A . Schwartz. Issues in using function approximation for reinforcement learning. In Proceedings of the Fourth Connectionist Models Summer School, 1993. [Watkins, 1989] C . Watkins. Learning from Delayed Rewards. PhD thesis, Cambridge University, 1989 . [Williams, 1993] R. Williams . Tight performance bounds on greedy policies based on imperfect value functions . Technical Report NU-CCS-93-13, Northeastern University, 1993. [Yee, 1992] R . Yee. sachusetts, 1992. Abstraction in control learning. Technical Report COINS 92-16 , Univ. of Mas- '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics, \n",
    "            random_state=100,\n",
    "            update_every=1,\n",
    "            chunksize=100,\n",
    "            passes=10,\n",
    "            alpha='auto',\n",
    "            per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_words_bigrams, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare:\n",
    "    lda_model_opt = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=8, \n",
    "        random_state=100,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True)\n",
    "    lda_model_opt.save('lda_opt.pkl')\n",
    "else:\n",
    "    lda_model_opt = gensim.models.ldamodel.LdaModel.load('lda_opt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.013*\"model\" + 0.012*\"neuron\" + 0.009*\"time\" + 0.008*\"cell\" + '\n",
      "  '0.007*\"neural\" + 0.007*\"figure\" + 0.007*\"signal\" + 0.007*\"system\" + '\n",
      "  '0.007*\"response\" + 0.006*\"activity\"'),\n",
      " (1,\n",
      "  '0.014*\"algorithm\" + 0.013*\"graph\" + 0.012*\"node\" + 0.009*\"set\" + '\n",
      "  '0.008*\"time\" + 0.008*\"cluster\" + 0.007*\"clustering\" + 0.007*\"structure\" + '\n",
      "  '0.007*\"number\" + 0.006*\"tree\"'),\n",
      " (2,\n",
      "  '0.050*\"network\" + 0.022*\"neural\" + 0.017*\"input\" + 0.015*\"learning\" + '\n",
      "  '0.015*\"layer\" + 0.013*\"output\" + 0.012*\"weight\" + 0.012*\"training\" + '\n",
      "  '0.012*\"unit\" + 0.008*\"function\"'),\n",
      " (3,\n",
      "  '0.032*\"image\" + 0.012*\"object\" + 0.012*\"model\" + 0.011*\"feature\" + '\n",
      "  '0.007*\"using\" + 0.007*\"convolutional\" + 0.006*\"representation\" + '\n",
      "  '0.006*\"map\" + 0.006*\"method\" + 0.006*\"recognition\"'),\n",
      " (4,\n",
      "  '0.016*\"algorithm\" + 0.012*\"function\" + 0.010*\"problem\" + 0.008*\"bound\" + '\n",
      "  '0.008*\"matrix\" + 0.008*\"method\" + 0.007*\"theorem\" + 0.006*\"learning\" + '\n",
      "  '0.006*\"result\" + 0.006*\"log\"'),\n",
      " (5,\n",
      "  '0.031*\"model\" + 0.018*\"distribution\" + 0.013*\"data\" + 0.009*\"log\" + '\n",
      "  '0.009*\"parameter\" + 0.008*\"sample\" + 0.008*\"inference\" + 0.008*\"gaussian\" + '\n",
      "  '0.008*\"variable\" + 0.007*\"method\"'),\n",
      " (6,\n",
      "  '0.016*\"learning\" + 0.015*\"model\" + 0.013*\"data\" + 0.012*\"task\" + '\n",
      "  '0.012*\"feature\" + 0.012*\"training\" + 0.009*\"set\" + 0.008*\"classification\" + '\n",
      "  '0.008*\"label\" + 0.007*\"class\"'),\n",
      " (7,\n",
      "  '0.018*\"state\" + 0.015*\"learning\" + 0.014*\"policy\" + 0.012*\"action\" + '\n",
      "  '0.011*\"algorithm\" + 0.009*\"time\" + 0.009*\"reward\" + 0.008*\"regret\" + '\n",
      "  '0.008*\"value\" + 0.008*\"agent\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model_opt.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_rl1 = '''Deep reinforcement learning on Atari games maps pixel directly to actions; internally,\n",
    "the deep neural network bears the responsibility of both extracting useful\n",
    "information and making decisions based on it. Aiming at devoting entire deep\n",
    "networks to decision making alone, we propose a new method for learning policies\n",
    "and compact state representations separately but simultaneously for policy\n",
    "approximation in reinforcement learning. State representations are generated by a\n",
    "novel algorithm based on Vector Quantization and Sparse Coding, trained online\n",
    "along with the network, and capable of growing its dictionary size over time. We\n",
    "also introduce new techniques allowing both the neural network and the evolution\n",
    "strategy to cope with varying dimensions. This enables networks of only 6 to 18\n",
    "neurons to learn to play a selection of Atari games with performance comparable—\n",
    "and occasionally superior—to state-of-the-art techniques using evolution strategies\n",
    "on deep networks two orders of magnitude larger.'''\n",
    "\n",
    "\n",
    "doc_rl2 = '''Deep reinforcement learning methods traditionally struggle with tasks where environment\n",
    "rewards are particularly sparse. One successful method of guiding\n",
    "exploration in these domains is to imitate trajectories provided by a human demonstrator.\n",
    "However, these demonstrations are typically collected under artificial\n",
    "conditions, i.e. with access to the agent’s exact environment setup and the demonstrator’s\n",
    "action and reward trajectories. Here we propose a two-stage method that\n",
    "overcomes these limitations by relying on noisy, unaligned footage without access\n",
    "to such data. First, we learn to map unaligned videos from multiple sources to a\n",
    "common representation using self-supervised objectives constructed over both time\n",
    "and modality (i.e. vision and sound). Second, we embed a single YouTube video\n",
    "in this representation to construct a reward function that encourages an agent to\n",
    "imitate human gameplay. This method of one-shot imitation allows our agent to\n",
    "convincingly exceed human-level performance on the infamously hard exploration\n",
    "games MONTEZUMA’S REVENGE, PITFALL! and PRIVATE EYE for the first time†\n",
    ",\n",
    "even if the agent is not presented with any environment rewards.\n",
    "'''\n",
    "\n",
    "doc_cv = '''Convolutional Neural Networks (CNNs) have become the method of choice \n",
    "for learning problems involving 2D planar images. However, a number of problems of recent \n",
    "interest have created a demand for models that can analyze spherical images. \n",
    "Examples include omnidirectional vision for drones, robots, and autonomous cars, \n",
    "molecular regression problems, and global weather and climate modelling. \n",
    "A naive application of convolutional networks to a planar projection of the spherical signal\n",
    "is destined to fail, because the space-varying distortions introduced by such a projection will\n",
    "make translational weight sharing ineffective.\n",
    "In this paper we introduce the building blocks for constructing spherical CNNs. \n",
    "We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant.\n",
    "The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute \n",
    "it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm.\n",
    "We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical \n",
    "CNNs applied to 3D model recognition and atomization energy regression.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc2bowl_bigram(doc):\n",
    "    doc = clean(doc)\n",
    "    words = doc_to_words(doc, stop_words, lemma)\n",
    "    bigrams = bigram_mod[words]\n",
    "    bow = id2word.doc2bow(bigrams)\n",
    "    return bow, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_rl1, bigrams_rl1 = doc2bowl_bigram(doc_rl1)\n",
    "bow_rl2, bigrams_rl2 = doc2bowl_bigram(doc_rl2)\n",
    "bow_cv, bigrams_cv = doc2bowl_bigram(doc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'reinforcement',\n",
       " 'learning',\n",
       " 'atari_game',\n",
       " 'map',\n",
       " 'pixel',\n",
       " 'directly',\n",
       " 'action',\n",
       " 'internally',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'bear',\n",
       " 'responsibility',\n",
       " 'extracting',\n",
       " 'useful',\n",
       " 'information',\n",
       " 'making',\n",
       " 'decision',\n",
       " 'based',\n",
       " 'aiming',\n",
       " 'devoting',\n",
       " 'entire',\n",
       " 'deep',\n",
       " 'network',\n",
       " 'decision',\n",
       " 'making',\n",
       " 'alone',\n",
       " 'propose',\n",
       " 'new',\n",
       " 'method',\n",
       " 'learning',\n",
       " 'policy',\n",
       " 'compact',\n",
       " 'state',\n",
       " 'representation',\n",
       " 'separately',\n",
       " 'simultaneously',\n",
       " 'policy',\n",
       " 'approximation',\n",
       " 'reinforcement',\n",
       " 'learning',\n",
       " 'state',\n",
       " 'representation',\n",
       " 'generated',\n",
       " 'novel',\n",
       " 'algorithm',\n",
       " 'based',\n",
       " 'vector',\n",
       " 'quantization',\n",
       " 'sparse',\n",
       " 'coding',\n",
       " 'trained',\n",
       " 'online',\n",
       " 'along',\n",
       " 'network',\n",
       " 'capable',\n",
       " 'growing',\n",
       " 'dictionary',\n",
       " 'size',\n",
       " 'time',\n",
       " 'also',\n",
       " 'introduce',\n",
       " 'new',\n",
       " 'technique',\n",
       " 'allowing',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'evolution',\n",
       " 'strategy',\n",
       " 'cope',\n",
       " 'varying',\n",
       " 'dimension',\n",
       " 'enables',\n",
       " 'network',\n",
       " 'neuron',\n",
       " 'learn',\n",
       " 'play',\n",
       " 'selection',\n",
       " 'atari_game',\n",
       " 'performance',\n",
       " 'comparable',\n",
       " 'occasionally',\n",
       " 'superior',\n",
       " 'state',\n",
       " 'art',\n",
       " 'technique',\n",
       " 'using',\n",
       " 'evolution',\n",
       " 'strategy',\n",
       " 'deep',\n",
       " 'network',\n",
       " 'two',\n",
       " 'order',\n",
       " 'magnitude',\n",
       " 'larger']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_rl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.3263107),\n",
       " (3, 0.2581074),\n",
       " (4, 0.017848648),\n",
       " (6, 0.026870906),\n",
       " (7, 0.34916314)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt.get_document_topics(bow_rl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.29723138),\n",
       " (4, 0.015419452),\n",
       " (5, 0.03982899),\n",
       " (6, 0.11953734),\n",
       " (7, 0.50085264)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt.get_document_topics(bow_rl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.029139243),\n",
       " (1, 0.11906097),\n",
       " (2, 0.077320196),\n",
       " (3, 0.44559783),\n",
       " (4, 0.16184708),\n",
       " (5, 0.11535659),\n",
       " (7, 0.043800566)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt.get_document_topics(bow_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bow2feat(bow):\n",
    "    return np.asarray([x for _, x in lda_model.get_document_topics(bow, minimum_probability=0)])\n",
    "\n",
    "\n",
    "def doc2feat(doc):\n",
    "    bow, _ = doc2bowl_bigram(doc)\n",
    "    return bow2feat(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_rl1 = doc2feat(doc_rl1)\n",
    "feat_rl2 = doc2feat(doc_rl2)\n",
    "feat_cv = doc2feat(doc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00347409, 0.00494003, 0.01583711, 0.04266278, 0.01496889,\n",
       "       0.01671956, 0.0161709 , 0.00446689, 0.03555086, 0.00768752,\n",
       "       0.00424144, 0.02585269, 0.02773212, 0.12899452, 0.28083357,\n",
       "       0.02106646, 0.00525921, 0.29093683, 0.02459397, 0.02801055],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(feat_rl1.shape)\n",
    "feat_rl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1: rl1, doc2: rl2, similarity 0.27\n",
      "doc1: rl1, doc2: cv, similarity 0.48\n",
      "doc1: rl2, doc2: cv, similarity 0.48\n"
     ]
    }
   ],
   "source": [
    "names = ['rl1', 'rl2', 'cv']\n",
    "feats = [feat_rl1, feat_rl2, feat_cv]\n",
    "names_feat = zip(names, feats)\n",
    "\n",
    "for (n1, f1), (n2, f2) in combinations(names_feat, 2):\n",
    "    print('doc1: {}, doc2: {}, similarity {:.2f}'.format(n1, n2, distance.euclidean(f1, f2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russian example\n",
    "\n",
    "https://github.com/maxoodf/russian_news_corpus\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/maxoodf/russian_news_corpus.git\n",
    "cd ./russian_news_corpus\n",
    "cat ./russian_news.txt.bz2_a* | bzip2 -d > ./russian_news.txt\n",
    "cat russian_news.txt | awk 'BEGIN {srand()} !/^$/ { if (rand() <= .005) print $0}' > russian_news_10k.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ru = Path('/media/storage/data_nlp/russian_news_corpus/russian_news_10k.txt').read_text(encoding='utf-8').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_words_ru(doc, stop_words):\n",
    "    stop_words = set(stop_words)\n",
    "    # remove stop words and punctuation\n",
    "    words = [w for w in gensim.utils.simple_preprocess(str(doc), deacc=True, max_len=100) if w not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepare = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ru = [clean(t) for t in data_ru]\n",
    "data_words_ru = [doc_to_words_ru(t, stop_words) for t in data_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сми',\n",
       " 'называть',\n",
       " 'украина',\n",
       " 'коррумпированныи',\n",
       " 'болото',\n",
       " 'мир',\n",
       " 'политика',\n",
       " 'аргумент',\n",
       " 'факт',\n",
       " 'москва']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_ru[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram_ru = gensim.models.Phrases(data_words_ru, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod_ru = gensim.models.phrases.Phraser(bigram_ru)\n",
    "    \n",
    "data_words_bigrams_ru = [bigram_mod_ru[w] for w in data_words_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['цивилизованныи',\n",
       " 'подход',\n",
       " 'наркоз',\n",
       " 'город',\n",
       " 'новость',\n",
       " 'санкт_петербург',\n",
       " 'фонтанка_ру',\n",
       " 'приморскии',\n",
       " 'раион',\n",
       " 'петербург']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_bigrams_ru[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_ru = corpora.Dictionary(data_words_bigrams_ru)\n",
    "corpus_ru = [id2word_ru.doc2bow(text) for text in data_words_bigrams_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_ru = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus_ru,\n",
    "    id2word=id2word_ru,\n",
    "    num_topics=20, \n",
    "    random_state=100,\n",
    "    update_every=1,\n",
    "    chunksize=100,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.021*\"человек\" + 0.020*\"москва\" + 0.019*\"сообщать\" + 0.011*\"место\" + '\n",
      "  '0.011*\"происходить\" + 0.009*\"улица\" + 0.009*\"здание\" + 0.008*\"находиться\" + '\n",
      "  '0.008*\"мужчина\" + 0.008*\"погибать\"'),\n",
      " (1,\n",
      "  '0.027*\"сбербанк\" + 0.015*\"минфин\" + 0.015*\"снижаться\" + 0.011*\"магазин\" + '\n",
      "  '0.010*\"продукт\" + 0.010*\"ставка\" + 0.009*\"мост\" + 0.008*\"валюта\" + '\n",
      "  '0.008*\"реитинг\" + 0.008*\"выпуск\"'),\n",
      " (2,\n",
      "  '0.034*\"крым\" + 0.025*\"интернет\" + 0.023*\"депутат\" + 0.019*\"закон\" + '\n",
      "  '0.016*\"госдума\" + 0.012*\"законопроект\" + 0.008*\"депутат_госдума\" + '\n",
      "  '0.007*\"лнр\" + 0.007*\"нилов\" + 0.007*\"сеть\"'),\n",
      " (3,\n",
      "  '0.015*\"сирия\" + 0.014*\"военныи\" + 0.014*\"оон\" + 0.011*\"город\" + '\n",
      "  '0.010*\"посол\" + 0.010*\"сша\" + 0.009*\"сила\" + 0.009*\"нато\" + '\n",
      "  '0.008*\"россиискии\" + 0.008*\"россия\"'),\n",
      " (4,\n",
      "  '0.022*\"суд\" + 0.020*\"дело\" + 0.019*\"год\" + 0.009*\"сотрудник\" + '\n",
      "  '0.009*\"задерживать\" + 0.009*\"сообщать\" + 0.008*\"которыи\" + 0.008*\"бывшии\" + '\n",
      "  '0.006*\"убииство\" + 0.006*\"экс\"'),\n",
      " (5,\n",
      "  '0.008*\"роман\" + 0.008*\"иран\" + 0.006*\"израиль\" + 0.006*\"подарок\" + '\n",
      "  '0.006*\"штаб\" + 0.006*\"сохраняться\" + 0.006*\"южныи_осетия\" + 0.006*\"греция\" '\n",
      "  '+ 0.006*\"рокфеллер\" + 0.005*\"выставлять\"'),\n",
      " (6,\n",
      "  '0.011*\"система\" + 0.010*\"исследование\" + 0.009*\"ученыи\" + '\n",
      "  '0.008*\"специалист\" + 0.008*\"медведев\" + 0.007*\"программа\" + '\n",
      "  '0.006*\"развитие\" + 0.006*\"научныи\" + 0.006*\"врач\" + 0.005*\"работа\"'),\n",
      " (7,\n",
      "  '0.031*\"россия\" + 0.017*\"президент\" + 0.015*\"заявлять\" + 0.014*\"россиискии\" '\n",
      "  '+ 0.013*\"глава\" + 0.013*\"украина\" + 0.012*\"страна\" + 0.009*\"которыи\" + '\n",
      "  '0.008*\"сообщать\" + 0.008*\"год\"'),\n",
      " (8,\n",
      "  '0.037*\"это\" + 0.026*\"которыи\" + 0.017*\"весь\" + 0.015*\"свои\" + 0.015*\"мочь\" '\n",
      "  '+ 0.013*\"такои\" + 0.011*\"человек\" + 0.009*\"другои\" + 0.008*\"время\" + '\n",
      "  '0.008*\"говорить\"'),\n",
      " (9,\n",
      "  '0.019*\"ребенок\" + 0.018*\"город\" + 0.018*\"регион\" + 0.012*\"полицеискии\" + '\n",
      "  '0.011*\"тысяча\" + 0.010*\"житель\" + 0.008*\"человек\" + 0.008*\"область\" + '\n",
      "  '0.008*\"региональныи\" + 0.008*\"земля\"'),\n",
      " (10,\n",
      "  '0.075*\"сша\" + 0.050*\"трамп\" + 0.028*\"американскии\" + 0.018*\"дональд_трамп\" '\n",
      "  '+ 0.013*\"самолет\" + 0.009*\"вашингтон\" + 0.009*\"белыи_дом\" + 0.006*\"кадыров\" '\n",
      "  '+ 0.006*\"администрация\" + 0.005*\"штат\"'),\n",
      " (11,\n",
      "  '0.017*\"год\" + 0.008*\"ребенок\" + 0.008*\"женщина\" + 0.007*\"становиться\" + '\n",
      "  '0.007*\"день\" + 0.007*\"жизнь\" + 0.006*\"свои\" + 0.006*\"больница\" + '\n",
      "  '0.006*\"номер\" + 0.005*\"молодои\"'),\n",
      " (12,\n",
      "  '0.019*\"год\" + 0.010*\"фильм\" + 0.009*\"русскии\" + 0.008*\"музеи\" + '\n",
      "  '0.008*\"культура\" + 0.008*\"памятник\" + 0.007*\"театр\" + 0.007*\"советскии\" + '\n",
      "  '0.007*\"белоруссия\" + 0.006*\"история\"'),\n",
      " (13,\n",
      "  '0.023*\"год\" + 0.018*\"банк\" + 0.018*\"компания\" + 0.007*\"млн\" + '\n",
      "  '0.007*\"проект\" + 0.007*\"рубль\" + 0.006*\"которыи\" + 0.006*\"предприятие\" + '\n",
      "  '0.005*\"строительство\" + 0.005*\"получать\"'),\n",
      " (14,\n",
      "  '0.017*\"церковь\" + 0.016*\"турция\" + 0.012*\"турецкии\" + 0.011*\"храм\" + '\n",
      "  '0.009*\"грузия\" + 0.007*\"святои\" + 0.006*\"вчера\" + 0.006*\"собор\" + '\n",
      "  '0.006*\"акция_протест\" + 0.006*\"арена\"'),\n",
      " (15,\n",
      "  '0.020*\"новость\" + 0.016*\"газета_ru\" + 0.011*\"чемпионат\" + 0.009*\"также\" + '\n",
      "  '0.009*\"спортсмен\" + 0.008*\"соревнование\" + 0.007*\"испания\" + '\n",
      "  '0.007*\"праздник\" + 0.007*\"финал\" + 0.006*\"победитель\"'),\n",
      " (16,\n",
      "  '0.051*\"год\" + 0.011*\"составлять\" + 0.011*\"рост\" + 0.010*\"уровень\" + '\n",
      "  '0.010*\"рынок\" + 0.010*\"россия\" + 0.010*\"рубль\" + 0.010*\"экономика\" + '\n",
      "  '0.010*\"цена\" + 0.008*\"россиискии\"'),\n",
      " (17,\n",
      "  '0.024*\"донбасс\" + 0.021*\"военныи\" + 0.011*\"днр\" + 0.010*\"техника\" + '\n",
      "  '0.010*\"советник\" + 0.009*\"сторона\" + 0.009*\"армения\" + 0.008*\"боевои\" + '\n",
      "  '0.008*\"конфликт\" + 0.007*\"минобороны\"'),\n",
      " (18,\n",
      "  '0.027*\"великобритания\" + 0.027*\"лондон\" + 0.026*\"британскии\" + '\n",
      "  '0.020*\"газпром\" + 0.018*\"газ\" + 0.015*\"кндр\" + 0.013*\"восстанавливать\" + '\n",
      "  '0.011*\"спг\" + 0.010*\"отчет\" + 0.008*\"потребоваться\"'),\n",
      " (19,\n",
      "  '0.022*\"матч\" + 0.021*\"команда\" + 0.014*\"сборная\" + 0.013*\"клуб\" + '\n",
      "  '0.012*\"россия\" + 0.011*\"спорт\" + 0.010*\"игра\" + 0.010*\"первыи\" + '\n",
      "  '0.008*\"футболист\" + 0.008*\"второи\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model_ru.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lda_ru', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        \"data_ru\": data_ru,\n",
    "        \"data_words_ru\": data_words_ru,\n",
    "        \"bigram_mod_ru\": bigram_mod_ru,\n",
    "        \"data_words_bigrams_ru\": data_words_bigrams_ru,\n",
    "        \"id2word_ru\": id2word_ru,\n",
    "        \"corpus_ru\": corpus_ru,\n",
    "        \"lda_model_ru\": lda_model_ru,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list_ru, coherence_values_ru = compute_coherence_values(\n",
    "    dictionary=id2word_ru, corpus=corpus_ru, texts=data_words_bigrams_ru, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_ru)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_opt_ru = model_list_ru[2]\n",
    "lda_model_opt_ru.save('lda_model_opt_ru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"человек\" + 0.015*\"москва\" + 0.013*\"сообщать\" + 0.010*\"место\" + 0.010*\"город\" + 0.010*\"происходить\" + 0.008*\"дом\" + 0.008*\"улица\" + 0.007*\"здание\" + 0.007*\"данные\"'),\n",
       " (1,\n",
       "  '0.039*\"год\" + 0.025*\"банк\" + 0.014*\"рубль\" + 0.012*\"составлять\" + 0.012*\"компания\" + 0.011*\"рынок\" + 0.009*\"рост\" + 0.009*\"млн\" + 0.009*\"цена\" + 0.008*\"млрд\"'),\n",
       " (2,\n",
       "  '0.015*\"крым\" + 0.009*\"новыи\" + 0.009*\"ребенок\" + 0.007*\"завод\" + 0.007*\"интернет\" + 0.007*\"работа\" + 0.007*\"специалист\" + 0.007*\"ученыи\" + 0.006*\"школа\" + 0.006*\"год\"'),\n",
       " (3,\n",
       "  '0.025*\"суд\" + 0.023*\"дело\" + 0.012*\"год\" + 0.012*\"задерживать\" + 0.009*\"сотрудник\" + 0.008*\"убииство\" + 0.008*\"которыи\" + 0.007*\"полиция\" + 0.007*\"бывшии\" + 0.006*\"мвд\"'),\n",
       " (4,\n",
       "  '0.022*\"год\" + 0.019*\"сообщать\" + 0.015*\"москва\" + 0.015*\"россия\" + 0.013*\"риа_новость\" + 0.012*\"россиискии\" + 0.011*\"март\" + 0.009*\"новость\" + 0.008*\"тасс\" + 0.006*\"проходить\"'),\n",
       " (5,\n",
       "  '0.012*\"аукцион\" + 0.012*\"грузия\" + 0.010*\"чечня\" + 0.009*\"дипломат\" + 0.007*\"месторождение\" + 0.006*\"дочка\" + 0.006*\"южныи_осетия\" + 0.005*\"заранее\" + 0.005*\"ирландскии\" + 0.005*\"повторять\"'),\n",
       " (6,\n",
       "  '0.017*\"это\" + 0.014*\"которыи\" + 0.014*\"россия\" + 0.013*\"год\" + 0.010*\"россиискии\" + 0.009*\"страна\" + 0.009*\"мочь\" + 0.008*\"наш\" + 0.008*\"новыи\" + 0.007*\"отмечать\"'),\n",
       " (7,\n",
       "  '0.023*\"россия\" + 0.021*\"президент\" + 0.019*\"сша\" + 0.018*\"заявлять\" + 0.016*\"украина\" + 0.012*\"страна\" + 0.011*\"глава\" + 0.011*\"трамп\" + 0.010*\"это\" + 0.010*\"россиискии\"'),\n",
       " (8,\n",
       "  '0.013*\"партия\" + 0.009*\"депутат\" + 0.008*\"выборы\" + 0.008*\"которыи\" + 0.007*\"свои\" + 0.007*\"проходить\" + 0.006*\"год\" + 0.005*\"митинг\" + 0.005*\"власть\" + 0.005*\"парламент\"'),\n",
       " (9,\n",
       "  '0.023*\"военныи\" + 0.013*\"полицеискии\" + 0.011*\"город\" + 0.010*\"территория\" + 0.009*\"раион\" + 0.008*\"сирия\" + 0.007*\"минобороны\" + 0.007*\"днр\" + 0.007*\"сила\" + 0.007*\"донбасс\"'),\n",
       " (10,\n",
       "  '0.017*\"год\" + 0.008*\"фильм\" + 0.008*\"становиться\" + 0.006*\"культура\" + 0.006*\"церковь\" + 0.006*\"русскии\" + 0.006*\"музеи\" + 0.005*\"театр\" + 0.005*\"которыи\" + 0.004*\"новыи\"'),\n",
       " (11,\n",
       "  '0.026*\"это\" + 0.015*\"которыи\" + 0.014*\"свои\" + 0.012*\"весь\" + 0.011*\"человек\" + 0.009*\"такои\" + 0.009*\"мочь\" + 0.007*\"самыи\" + 0.006*\"другои\" + 0.006*\"время\"'),\n",
       " (12,\n",
       "  '0.016*\"команда\" + 0.016*\"матч\" + 0.010*\"сборная\" + 0.010*\"россия\" + 0.009*\"клуб\" + 0.009*\"спорт\" + 0.008*\"первыи\" + 0.008*\"новость\" + 0.007*\"игра\" + 0.006*\"второи\"'),\n",
       " (13,\n",
       "  '0.016*\"год\" + 0.010*\"которыи\" + 0.010*\"компания\" + 0.008*\"решение\" + 0.008*\"закон\" + 0.006*\"это\" + 0.006*\"принимать\" + 0.006*\"мочь\" + 0.005*\"получать\" + 0.005*\"также\"')]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt_ru.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
