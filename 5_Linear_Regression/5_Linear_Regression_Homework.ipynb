{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    " Построение модели линейной регрессии, настройка гиперпараметров на кросс-валидации, интерпретация коэффициентов.\n",
    "\n",
    "## Цель: \n",
    "В этом дз вы потренируетесь строить интерпретируемые модели линейной регрессии с регуляризацией и без. Снова пройдемся по основным этапам работы с данными и на выходе получим модели, способные предсказывать цены на жильё в AirBnb.\n",
    "Снова предсказание цены квартиры, но на сей раз съемной :)\n",
    "\n",
    "1. Скачайте данные с Kaggle по ценам на жильё в Airbnb в Нью-Йорке:\n",
    "https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data\n",
    "\n",
    "2. Пройдите по основным шагам работы с данными - базовые статистики, визуализации (распределения, корреляции, pair plots), предобработка переменных.\n",
    "\n",
    "`Переменные, которые пока нужно убрать: id, name, host_id, host_name, last_review.`\n",
    "\n",
    "Обратите внимание на распределение целевой переменной.\n",
    "\n",
    "Во время предобработки не забудьте закодировать категориальные переменные (one-hot encoding, можно использовать pd.get_dummies) и прошкалировать непрерывные.\n",
    "\n",
    "Бонусное задание по предобработке - найдите координаты центра Нью-Йорка и при помощи евклидового расстояния создайте новую переменную \"center_distance\" используя широту и долготу центра и текущей квартиры. Этот признак для линейной регрессии будет работать гораздо лучше, чем просто широта и долгота, так что их можно будет спокойно убрать из датасета.\n",
    "\n",
    "3. Отложите 30% данных для тестирования и постройте модели простой линейной регрессии, RidgeCV, LassoCV и ElasticNetCV. Измерьте качество каждой и визуализируйте важность признаков. Сделайте интересные выводы :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               # уже знакомый вам пакет для работы с таблицами\n",
    "import numpy as np                # смутно знакомый вам пакет для работы с матрицами\n",
    "import matplotlib.pyplot as plt   # уже знакомый вам пакет для картинок \n",
    "import matplotlib as mplt\n",
    "import seaborn as sns             # ещё один пакет для картинок \n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/AB_NYC_2019.csv')  # подгружаем табличку \n",
    "print('Размер выборки:', df.shape)                          # смотрим на её размеры \n",
    "df.head( ) # Смотрим что лежит в табличке "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соответствии с заданием удаляем признаки:\n",
    "`id, name, host_id, host_name, last_review`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'name', 'host_id', 'host_name', 'last_review'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Анализ целевой переменной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой переменной является `price` - цена аренды за сутки. Выведем ее гистограмму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно, что переменная имеет длинный \"хвост\" и принимает `нулевые!` значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выбросы в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['price']].describe(percentiles=[.25, .5, .75, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение значения `95%, 99%` перцентиля с `max` занчением показывает, что цена за сутки `95%` квартир не превышает `$355`, для `99%` не превышает `$799`, а максимальная цена составляет `$10000`. Таким образом удалять данные не стоит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим данные, в которых значение признака `price` равно 0 и и проведем логарифмирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df[df['price'] == 0].index, inplace=True)\n",
    "df['price'] = np.log(df['price'])\n",
    "df['price'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Анализ признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные на пропуски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True);\n",
    "\n",
    "reviews_per_month_len = len(df[~df['reviews_per_month'].isna()])\n",
    "df_len = len(df)\n",
    "\n",
    "print(\"\\nДанных в `reviews_per_month` меньше на {}% относительно остальных признаков.\".format(\n",
    "    round(100 - 100 * reviews_per_month_len / df_len))\n",
    "     )\n",
    "\n",
    "print('\\nПосмотрим, сколько в данных NaN значений:\\n')\n",
    "print(df.isnull().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсутствие 21% данных не является критичным. Также не обходимо заполнить пропуски в признаке `reviews_per_month`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество признаков по типам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_series().groupby([df.dtypes,df.columns]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из 11 признаков, только 3 категориальные: `neighbourhood, neighbourhood_group, room_type`.\n",
    "Рассмотрим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['room_type'].value_counts().plot(kind='pie', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что есть преобладание признаков `private room`,`entire home/apt` над `shared room`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neighbourhood_group'].value_counts().plot(kind='pie', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Болшье всего жилья сдается в боро `Brooklyn` и `Manhattan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neighbourhood'].value_counts().plot(kind='pie', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень удачная визуализация, но наглядно отображает распределение районов. Районы входят в состав боро, таким образом можно сделать вывод, что вклад данных по районам включен в данные боро. И эти признаки можно либо удалить либо кластеризовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим выбросы в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('price',axis=1).describe(percentiles=[.25, .5, .75, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки `minimum_nights, reviews_per_month` имеют явные выбросы, так как `99%` данных имеют значением на порядки меньше максимального значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=[\"minimum_nights\"], data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько данных у признака `minimum_nights` больше `600`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['minimum_nights'] > 600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим их из выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df[df['minimum_nights'] > 600].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=[\"reviews_per_month\"], data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько данных у признака reviews_per_month больше 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['reviews_per_month'] > 35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим значение из выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df[df['reviews_per_month'] > 35].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим диаграммы распределений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из диаграмм видно, что `price` не имеет линейной зависимости от `latitude,longitude`. Но видна зависимость `reviews_per_month` от `number_of_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.scatterplot(x=df['number_of_reviews'],y=df['reviews_per_month'], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим корреляцию признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(df.corr(), annot=True, linewidths=1, fmt='.2f',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явной корреляции не наблюдается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим гистограммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('price',axis=1).hist(figsize=(20, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение близкое к нормальному имеют только признаки `latitude,longitude`, что очевидно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обработка пропущенных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо заполнить пропуски данных для признака `reviews_per_month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df[[\n",
    "    'latitude', 'longitude', 'price', 'minimum_nights', \n",
    "    'number_of_reviews', 'reviews_per_month', \n",
    "    'calculated_host_listings_count', 'availability_365'\n",
    "]].copy()\n",
    "df_reviews[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['reviews_per_month'] = np.where(df_reviews['number_of_reviews']!=0, df_reviews['reviews_per_month'],.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y_train = df_reviews['reviews_per_month']\n",
    "X_train = df_reviews.drop('reviews_per_month', axis = 1)\n",
    "print(X_train.shape)\n",
    "model_regression = LinearRegression()\n",
    "model_regression.fit(X_train, y_train)\n",
    "\n",
    "df_reviews['reviews_per_month_pred'] = model_regression.predict(df_reviews.drop('reviews_per_month', axis = 1))\n",
    "df['reviews_per_month'] = np.where(~df_reviews['reviews_per_month'].isnull(),df_reviews['reviews_per_month'],df_reviews['reviews_per_month_pred'])\n",
    "del df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наши данные не содержат пропусков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Подготовка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из предположения выше о важности признака `neighbourhood` и что его данные уже содержаться в `neighbourhood_group` - удали этот признак. Остальные категориальные признаки преобразуем с помошью `get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['neighbourhood'], inplace=True, axis=1)\n",
    "\n",
    "df_dumm = pd.get_dummies(df[['neighbourhood_group','room_type']])\n",
    "\n",
    "df = pd.concat([df.drop(['neighbourhood_group','room_type'],axis=1),df_dumm], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим центр масс координат с помощью нахождения медианы. Созданим новый признак `center_distance` и включим его в выборку. Признаки `latitude, longitude` искллючим из выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_phi,center_lambda = df['latitude'].median(), df['longitude'].median()\n",
    "print('Координаты центра:',center_phi,center_lambda)\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "df['center_distance'] = euclidean_distances(df[['latitude','longitude']],[[center_phi,center_lambda]])\n",
    "df.drop(columns=['latitude','longitude'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим нашу выборку на тренировочную и проверочную и производем шкалирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_train[[\n",
    "    'minimum_nights','number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count','availability_365','center_distance'\n",
    "]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scale = scaler.transform(\n",
    "    df_train[[\n",
    "        'minimum_nights','number_of_reviews','reviews_per_month',\n",
    "        'calculated_host_listings_count','availability_365','center_distance'\n",
    "    ]]\n",
    ")\n",
    "\n",
    "df_test_scale = scaler.transform(\n",
    "    df_test[[\n",
    "        'minimum_nights','number_of_reviews','reviews_per_month',\n",
    "        'calculated_host_listings_count','availability_365','center_distance'\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[[\n",
    "    'minimum_nights','number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count','availability_365','center_distance'\n",
    "]] = df_train_scale\n",
    "\n",
    "df_test[[\n",
    "    'minimum_nights','number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count','availability_365','center_distance'\n",
    "]] = df_test_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape) # Посмотрим на размеры трэйна и теста \n",
    "print(df_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевую переменную и признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.price \n",
    "y_test = df_test.price \n",
    "\n",
    "X_train = df_train.drop('price', axis=1).get_values()\n",
    "X_test = df_test.drop('price', axis=1).get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Базовая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим базовую модель на основе среднего значения целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(y_train)\n",
    "y_pred_naive = np.ones(len(y_test)) * y_mean  \n",
    "y_pred_naive[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def print_metrics(y_test,y_pred,values=False):\n",
    "    mae = metrics.mean_absolute_error(np.exp(y_test), np.exp(y_pred))\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    if values:\n",
    "        return {'MAE':mae, 'RMSE':rmse, 'R2':r2, 'MAPE':mape}\n",
    "    \n",
    "    print('MAE:', mae)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2:',  r2)\n",
    "    print('MAPE:', mape)\n",
    "    pass\n",
    "    \n",
    "\n",
    "print_metrics(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию построения графика важности признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_plot(df, model_coef, figsize=(10,6)):\n",
    "    featureImportance = pd.DataFrame({\"feature\": df.drop('price',axis=1).columns, \n",
    "                                  \"importance\": model_coef})\n",
    "    \n",
    "    featureImportance.set_index('feature', inplace=True)\n",
    "    featureImportance.sort_values([\"importance\"], ascending=False, inplace=True)\n",
    "    featureImportance[\"importance\"].plot('bar', figsize=figsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим простую линейную регрессию и выведем график важности признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_regression = LinearRegression()\n",
    "\n",
    "model_regression.fit(X_train, y_train)\n",
    "y_pred_regr = model_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_regr)\n",
    "importance_plot(df, model_regression.coef_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что положительно на цену влияют аренда все квартиры и ее расположение в боро Манхеттен, отрицательно влияют совместное проживание и удаленность от центра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем для модели лучшие параметры с помощью `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Решётака для перебора параметра \n",
    "param_grid = {'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 0.8, 1, 5, 10]}\n",
    "\n",
    "# Объявили модель \n",
    "model_lasso = Lasso() \n",
    "\n",
    "# Объявили перебор \n",
    "grid_cv_lasso = GridSearchCV(model_lasso, param_grid, cv = 5)\n",
    "grid_cv_lasso.fit(X_train, y_train)\n",
    "print('Лучшее значение параметра:', grid_cv_lasso.best_params_)\n",
    "\n",
    "# Сделали прогнозы\n",
    "y_pred_lasso = grid_cv_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_lasso)\n",
    "importance_plot(df, grid_cv_lasso.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главные признаки остались без изменений, а вот отрицательное влияние цену теперь указывают вторичные признаки: проживание в боро Бруклин и Куинс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем для модели лучшие параметры с помощью RidgeCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "\n",
    "model_ridge = Ridge() \n",
    "\n",
    "ridge_cv_ridge = RidgeCV(alphas=[0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 0.8, 1, 5, 10],store_cv_values=True)\n",
    "ridge_cv_ridge.fit(X_train, y_train)\n",
    "print('Лучшее значение параметра:', ridge_cv_ridge.cv_values_[0][0])\n",
    "\n",
    "# # Сделали прогнозы\n",
    "y_pred_ridge = ridge_cv_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_lasso)\n",
    "importance_plot(df, ridge_cv_ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главные признаки `RidgeCV` не изменила, а среди вторичных отрицательных отметила проживание в частной комнате и удаленность от центра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем для модели лучшие параметры с помощью ElasticNetCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV,ElasticNet\n",
    "\n",
    "model_elastic = ElasticNet() \n",
    "\n",
    "elastic_cv_elastic = ElasticNetCV(cv=5, random_state=42)\n",
    "elastic_cv_elastic.fit(X_train, y_train)\n",
    "print('Лучшее значение параметра:', elastic_cv_elastic.alpha_)\n",
    "\n",
    "# # Сделали прогнозы\n",
    "y_pred_elastic = elastic_cv_elastic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_elastic)\n",
    "importance_plot(df, elastic_cv_elastic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главные признаки ElasticNetCV сообтветствуют RidgeCV, но в качестве вторичных отрицательных выделено расстояние от центра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_y_pred_naive = print_metrics(y_test,y_pred_naive,values=True)\n",
    "d_y_pred_naive.update({'Name':'Naive'})\n",
    "\n",
    "d_y_pred_regr = print_metrics(y_test,y_pred_regr,values=True)\n",
    "d_y_pred_regr.update({'Name':'Simple Linear'})\n",
    "\n",
    "d_y_pred_lasso = print_metrics(y_test,y_pred_lasso,values=True)\n",
    "d_y_pred_lasso.update({'Name':'GridSearchCV'})\n",
    "\n",
    "d_y_pred_ridge = print_metrics(y_test,y_pred_ridge,values=True)\n",
    "d_y_pred_ridge.update({'Name':'RidgeCV'})\n",
    "\n",
    "d_y_pred_elastic = print_metrics(y_test,y_pred_elastic,values=True)\n",
    "d_y_pred_elastic.update({'Name':'ElasticNetCV'})\n",
    "\n",
    "\n",
    "df_summary = pd.DataFrame([d_y_pred_naive,d_y_pred_regr,d_y_pred_lasso,d_y_pred_ridge,d_y_pred_elastic])\n",
    "df_summary.set_index('Name',inplace=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. По абсолютной ошибке `MAE` лучший результат у `ElasticNetCV` = `$64.586`\n",
    "1. По корню из квадратичной ошибки `RMSE` лучший результат у `Simple Linear` = `$248.794`\n",
    "1. Наиболее лучше обясняет данные `Simple Linear`, где  `R2` = `0.496517`\n",
    "1. По средней абсолютной ошибке `MAPE`, лучшая модель `Simple Linear` = `7.5618`\n",
    "1. Главный признак, положительно вляющий на цену - это арнеда полностью всей квартиры `room type` = `rntire home/apt`\n",
    "1. Главный признак, отрицательно влияющий на цену - это совместная аренда квартиры `room type` = `shared room`\n",
    "1. Вторично отрицательно на цену влияют: `center distance`, `room type` = `private room`, `neighbourhood group` = `Brooklyn`\n",
    "1. Вторично положительно на цену влияют: `neighbourhood group` = `Manhattan` и `availability_365`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
